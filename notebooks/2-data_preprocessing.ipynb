{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acaafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba2f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "dataset_path = 'datasets'\n",
    "feature_store_file_path = os.path.join(dataset_path, 'creditcard.csv')\n",
    "target_column = 'Class'\n",
    "artifact_folder = 'artifacts'\n",
    "transformed_train_file_path: str = os.path.join(artifact_folder, 'train.csv')\n",
    "transformed_test_file_path: str = os.path.join(artifact_folder, 'test.csv')\n",
    "RANDOM_STATE = 1\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff285a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data function\n",
    "def get_data(file_path: str) -> pd.DataFrame:\n",
    "\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4069201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the anomaly scores using Isolation Forest\n",
    "def get_anomaly_scores(X_train, X_test):\n",
    "    isolation_forest = IsolationForest(contamination=0.00172, random_state=1)\n",
    "    isolation_forest.fit(X_train)\n",
    "    \n",
    "    anomaly_scores_train = isolation_forest.decision_function(X_train)\n",
    "    anomaly_scores_test = isolation_forest.decision_function(X_test)\n",
    "    \n",
    "    return anomaly_scores_train, anomaly_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0288c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get data transformer object\n",
    "def get_data_transformer_object():\n",
    "    pca_features = ['V' + str(i) for i in range(1, 29)]\n",
    "    other_features = ['Time', 'Amount', 'anomaly_score']\n",
    "\n",
    "    pca_features_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median'))])\n",
    "    other_features_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('pca_features', pca_features_transformer, pca_features),\n",
    "            ('other_features', other_features_transformer, other_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "148f1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initiate data transformation\n",
    "def initiate_data_transformation():\n",
    "    # Load data\n",
    "    df = get_data(feature_store_file_path)\n",
    "\n",
    "    # Split data into features and target variable\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "    # Get anomaly scores for training data\n",
    "    anomaly_scores_train, anomaly_scores_test = get_anomaly_scores(X_train, X_test)\n",
    "\n",
    "    # Add anomaly scores to train and test data\n",
    "    X_train['anomaly_score'] = anomaly_scores_train\n",
    "    X_test['anomaly_score'] = anomaly_scores_test\n",
    "\n",
    "    # Get the data transformer object\n",
    "    preprocessor = get_data_transformer_object()\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test data\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Handle class imbalance using SMOTE\n",
    "    smote = SMOTETomek(random_state=1, sampling_strategy=0.2)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "    # Concatenate the transformed features and target variable\n",
    "    train_df = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "    train_df[target_column] = y_train_resampled\n",
    "    test_df = pd.DataFrame(X_test_transformed, columns=X_test.columns)\n",
    "    test_df[target_column] = y_test\n",
    "\n",
    "    # Save the transformed data\n",
    "    os.makedirs(artifact_folder, exist_ok=True)\n",
    "    train_df.to_csv(transformed_train_file_path, index=False)\n",
    "    test_df.to_csv(transformed_test_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee0585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_data_transformation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
